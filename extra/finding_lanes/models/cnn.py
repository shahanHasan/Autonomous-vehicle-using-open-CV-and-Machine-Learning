# -*- coding: utf-8 -*-
"""CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17tR2r_boc8yWu0swDn5gq1Rd17w9ENUM
"""

import numpy as np
import matplotlib.pyplot as plt
import keras
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Flatten
from keras.layers.convolutional import Conv2D
from keras.layers.convolutional import MaxPooling2D
from keras.optimizers import Adam
from keras.utils.np_utils import to_categorical
from keras.layers import Dropout
from keras.models import Model
import random


np.random.seed(0)




(X_train, y_train), (X_test, y_test)= mnist.load_data()

print(X_train.shape)
print(X_test.shape)
assert(X_train.shape[0] == y_train.shape[0]), "The number of images is not equal to the number of labels."
assert(X_train.shape[1:] == (28,28)), "The dimensions of the images are not 28 x 28."
assert(X_test.shape[0] == y_test.shape[0]), "The number of images is not equal to the number of labels."
assert(X_test.shape[1:] == (28,28)), "The dimensions of the images are not 28 x 28."

num_of_samples=[]
 
cols = 5
num_classes = 10

fig, axs = plt.subplots(nrows=num_classes, ncols=cols, figsize=(5,10))
fig.tight_layout()

for i in range(cols):
    for j in range(num_classes):
      x_selected = X_train[y_train == j]
      axs[j][i].imshow(x_selected[random.randint(0,(len(x_selected) - 1)), :, :], cmap=plt.get_cmap('gray'))
      axs[j][i].axis("off")
      if i == 2:
        axs[j][i].set_title(str(j))
        num_of_samples.append(len(x_selected))




print(num_of_samples)
plt.figure(figsize=(12, 4))
plt.bar(range(0, num_classes), num_of_samples)
plt.title("Distribution of the train dataset")
plt.xlabel("Class number")
plt.ylabel("Number of images")
plt.show()



X_train = X_train.reshape(60000, 28, 28, 1)
X_test = X_test.reshape(10000, 28, 28, 1)


y_train = to_categorical(y_train, 10)
y_test = to_categorical(y_test, 10)

X_train = X_train/255
X_test = X_test/255

# LEnet based model function (padding can be valid,casual , same)
def lenet_model():
  # create the model
  model = Sequential()
  # add convolution layer 1
  model.add(Conv2D(30, (5, 5), input_shape=(28,28,1), activation='relu', strides=1))
  # add pooling layer 1
  model.add(MaxPooling2D(pool_size=(2,2)))
  # add convolution layer 2
  model.add(Conv2D(15, (3,3), activation = 'relu', strides=1))
  # add pooling layer 2
  model.add(MaxPooling2D(pool_size=(2,2)))
  # flatten
  model.add(Flatten())
  # add hidden 1
  model.add(Dense(500, activation='relu'))
  # add hidden 2
  #model.add(Dense(300, activation='relu'))
  # add dropout layer , drops or shuts down nodes to decrease overfitting and generalisation error
  model.add(Dropout(0.5))
  # output layer 
  model.add(Dense(num_classes, activation='softmax'))
  # compiling the model
  model.compile(Adam(lr=0.01), loss='categorical_crossentropy', metrics=['accuracy'])
  return model

model = lenet_model()
print(model.summary())

# history
history = model.fit(X_train, y_train, epochs=30, validation_split=0.1, batch_size=400, verbose=1, shuffle=1)

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.legend(['loss', 'val_loss'])
plt.title('Loss')
plt.xlabel('epoch')

plt.plot(history.history['acc'])
plt.plot(history.history['val_acc'])
plt.legend(['acc', 'val_acc'])
plt.title('Accuracy')
plt.xlabel('epoch')

# random image predicition
import requests
from PIL import Image
url1='https://www.researchgate.net/profile/Jose_Sempere/publication/221258631/figure/fig1/AS:305526891139075@1449854695342/Handwritten-digit-2.png'
url = 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcST8KzXHtkSHcxzdpnllMhAj0upLEwnNFdtY6j4YUPcmaf4Ty3u'
response = requests.get(url, stream=True)
img = Image.open(response.raw)
plt.imshow(img, cmap=plt.get_cmap('gray'))

import cv2

img = np.asarray(img)
img = cv2.resize(img, (28, 28))
img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
img = cv2.bitwise_not(img)
plt.imshow(img, cmap=plt.get_cmap('gray'))

img = img/255
img = img.reshape(1, 28, 28, 1)

prediction = model.predict_classes(img)
print("predicted digit:", str(prediction))

# testing
score = model.evaluate(X_test, y_test, verbose=0)
print(type(score))
print('Test score:', score[0])
print('Test accuracy:', score[1])

# model of keras lets us use sections from previously trained model
layer1 = Model(inputs=model.layers[0].input,outputs=model.layers[0].output)
layer2 = Model(inputs=model.layers[0].input,outputs=model.layers[2].output)

visual_layer1, visual_layer2 = layer1.predict(img) , layer2.predict(img)
print(visual_layer1.shape)
print(visual_layer2.shape)

# outputs of the first convolution layer in terms of feature maps
plt.figure(figsize=(10,6))
for i in range(30):
  plt.subplot(6,5, i+1)
  plt.imshow(visual_layer1[0,:,:, i], cmap=plt.get_cmap('jet'))
  plt.axis('off')

# outputs of the 2nd convolution laye in term of feature maps
plt.figure(figsize=(10,6))
for i in range(15):
  plt.subplot(3,5, i+1)
  plt.imshow(visual_layer2[0,:,:, i], cmap=plt.get_cmap('jet'))
  plt.axis('off')

